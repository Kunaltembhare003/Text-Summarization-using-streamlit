{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85ce105-443c-41d9-bf8d-df72c34dfb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9d821e-7d0b-4634-b5ca-76c7195012c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (2.14.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: aiohttp in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: pandas in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (1.5.0)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: multiprocess in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90390635-7c0a-4eeb-8990-e6054f10d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc0e5e9-01b8-4c86-a619-72fdfa3c06f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (0.24.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from accelerate) (22.0)\n",
      "Requirement already satisfied: psutil in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: filelock in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: networkx in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: sympy in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: requests in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Found existing installation: transformers 4.34.1\n",
      "Uninstalling transformers-4.34.1:\n",
      "  Successfully uninstalled transformers-4.34.1\n",
      "Found existing installation: accelerate 0.24.0\n",
      "Uninstalling accelerate-0.24.0:\n",
      "  Successfully uninstalled accelerate-0.24.0\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.24.0-py3-none-any.whl (260 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: psutil in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/kunalt/Tools/miniconda3/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: transformers, accelerate\n",
      "Successfully installed accelerate-0.24.0 transformers-4.34.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate\n",
    "!pip uninstall -y transformers accelerate\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea2230a-c9c2-497a-b3d5-3fbeb344f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "#nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21bb0dd-2aaf-41f0-9381-66549104bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kunalt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23260fc3-464f-4e16-b3b2-86bbb03e8a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a9a8e46-cd4d-423c-b871-78aa0c4640a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88ca809371c48a6ad6e9a7ecb1b0c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb339d0c2754b218b8017334ea11b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2257cdcc34c0425fbba78c5128a232c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584f3ba316c249548d60555e91f14b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934b7ec30d92493a9ad7693d2cd3f6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f367c67ab53b453f8d0617bd0df29707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6da1bd-bc02-405d-b37d-4cfff0b4b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the CNN/DailyMail dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\",\"2.0.0\")\n",
    "\n",
    "# Access the training, validation, and test splits\n",
    "train_data = dataset[\"train\"]\n",
    "validation_data = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4332819-195f-4d31-95ab-4176dce36753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id'],\n",
       "    num_rows: 287113\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea695c4f-f119-4172-8e3f-d7ba707edc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Text:\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
      "\n",
      "Target Summary:\n",
      "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n"
     ]
    }
   ],
   "source": [
    "# Access the first example in the training split\n",
    "example = train_data[0]\n",
    "source_text = example[\"article\"]\n",
    "target_text = example[\"highlights\"]\n",
    "\n",
    "# Print the source text and target summary\n",
    "print(\"Source Text:\")\n",
    "print(source_text)\n",
    "print(\"\\nTarget Summary:\")\n",
    "print(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41956e6a-7475-448a-be6f-ceb4ea2c031e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split lengths: [287113, 13368, 11490]\n",
      "Features: ['article', 'highlights', 'id']\n",
      "\n",
      "article:\n",
      "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State University, where the dog -- a friendly white-and-black bully breed mix now named Theia -- has been receiving care at the Veterinary Teaching Hospital. Four days after her apparent death, the dog managed to stagger to a nearby farm, dirt-covered and emaciated, where she was found by a worker who took her to a vet for help. She was taken in by Moses Lake, Washington, resident Sara Mellado. \"Considering everything that she's been through, she's incredibly gentle and loving,\" Mellado said, according to WSU News. \"She's a true miracle dog and she deserves a good life.\" Theia is only one year old but the dog's brush with death did not leave her unscathed. She suffered a dislocated jaw, leg injuries and a caved-in sinus cavity -- and still requires surgery to help her breathe. The veterinary hospital's Good Samaritan Fund committee awarded some money to help pay for the dog's treatment, but Mellado has set up a fundraising page to help meet the remaining cost of the dog's care. She's also created a Facebook page to keep supporters updated. Donors have already surpassed the $10,000 target, inspired by Theia's tale of survival against the odds. On the fundraising page, Mellado writes, \"She is in desperate need of extensive medical procedures to fix her nasal damage and reset her jaw. I agreed to foster her until she finally found a loving home.\" She is dedicated to making sure Theia gets the medical attention she needs, Mellado adds, and wants to \"make sure she gets placed in a family where this will never happen to her again!\" Any additional funds raised will be \"paid forward\" to help other animals. Theia is not the only animal to apparently rise from the grave in recent weeks. A cat in Tampa, Florida, found seemingly dead after he was hit by a car in January, showed up alive in a neighbor's yard five days after he was buried by his owner. The cat was in bad shape, with maggots covering open wounds on his body and a ruined left eye, but remarkably survived with the help of treatment from the Humane Society.\n",
      "\n",
      "Summary:\n",
      "Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\n",
      "\"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n"
     ]
    }
   ],
   "source": [
    "split_lengths = [len(dataset[split])for split in dataset]\n",
    "\n",
    "print(f\"Split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset['train'].column_names}\")\n",
    "print(\"\\narticle:\")\n",
    "\n",
    "print(dataset[\"test\"][1][\"article\"])\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "\n",
    "print(dataset[\"test\"][1][\"highlights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1e64a0-945c-4507-9d98-18f5290a7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch['article'] , max_length = 1024, truncation = True )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch['highlights'], max_length = 128, truncation = True )\n",
    "\n",
    "    return {\n",
    "        'input_ids' : input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf2ef397-b64b-4612-bc9a-06c00a15af9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e54dfb1a2c42638b3e66d8f38a9d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunalt/Tools/miniconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3848: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3da56715d48494e9a80a479e4aaae08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d5cd16e0d146c7b516348a1f288eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_pt = dataset.map(convert_examples_to_features, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6406f56c-cd84-4833-b897-1344db21caa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 287113\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pt[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ebe974-e41a-4f9b-ae40-15b85b42173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fecc277b-405c-4009-9a4c-2c5b9e4d93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "trainer_args = TrainingArguments(\n",
    "    output_dir='/home/kunalt/Text/pegasus-cnndailymail', num_train_epochs=1, warmup_steps=500,\n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10,\n",
    "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "    gradient_accumulation_steps=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c63e15-a227-4c47-8666-31e137409503",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_pt[\"test\"],\n",
    "                  eval_dataset=dataset_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe1624e2-6dc6-4f20-8d54-ba2978de66ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='718' max='718' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [718/718 8:54:36, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.588600</td>\n",
       "      <td>1.429903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=718, training_loss=1.6934242859524273, metrics={'train_runtime': 32136.8977, 'train_samples_per_second': 0.358, 'train_steps_per_second': 0.022, 'total_flos': 2.370145546265395e+16, 'train_loss': 1.6934242859524273, 'epoch': 1.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3a26864-62db-4784-83da-5ee64fdec431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n",
    "\n",
    "        # Finally, we decode the generated texts,\n",
    "        # replace the  token, and add the decoded texts with the references to the metric.\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "\n",
    "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "\n",
    "\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    #  Finally compute and return the ROUGE scores.\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0c5fd0d-dc6d-425d-bd82-bdd51241626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90d6457b-feb2-44e7-8a69-e7d7adf7e427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44f4e5456a0416e9d98e609d746cb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_metric = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd8c7876-d5db-4cb8-a75e-c8ca805786f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 5/5 [01:01<00:00, 12.31s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'mid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m score \u001b[38;5;241m=\u001b[39m calculate_metric_on_test_ds(\n\u001b[1;32m      2\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m], rouge_metric, trainer\u001b[38;5;241m.\u001b[39mmodel, tokenizer, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, column_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m, column_summary\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighlights\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmeasure\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrouge_names\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m score \u001b[38;5;241m=\u001b[39m calculate_metric_on_test_ds(\n\u001b[1;32m      2\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m], rouge_metric, trainer\u001b[38;5;241m.\u001b[39mmodel, tokenizer, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, column_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m, column_summary\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighlights\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, \u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241m.\u001b[39mfmeasure ) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m rouge_names )\n\u001b[1;32m      7\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'mid'"
     ]
    }
   ],
   "source": [
    "score = calculate_metric_on_test_ds(\n",
    "    dataset['test'][0:10], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'article', column_summary= 'highlights'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee37d269-e7d3-4ba4-80f8-6e797972eaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.02015273712174629,\n",
       " 'rouge2': 0.002387620781403165,\n",
       " 'rougeL': 0.020328111308326118,\n",
       " 'rougeLsum': 0.0201563433024961}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c3f3b7-f215-4752-a6ac-57be83e14286",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'mid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmeasure\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrouge_names\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, \u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241m.\u001b[39mfmeasure ) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m rouge_names )\n\u001b[1;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rouge_dict, index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpegasus\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'mid'"
     ]
    }
   ],
   "source": [
    "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "\n",
    "pd.DataFrame(rouge_dict, index = [f'pegasus'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfc68710-b18f-41ca-82ac-d8d7efe4fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "model_pegasus.save_pretrained(\"/home/kunalt/Text/pegasus-cnn-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d97878e-a0a0-4b3d-8f68-1c44408a9fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/kunalt/Text/tokenizer/tokenizer_config.json',\n",
       " '/home/kunalt/Text/tokenizer/special_tokens_map.json',\n",
       " '/home/kunalt/Text/tokenizer/spiece.model',\n",
       " '/home/kunalt/Text/tokenizer/added_tokens.json',\n",
       " '/home/kunalt/Text/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save tokenizer\n",
    "tokenizer.save_pretrained(\"/home/kunalt/Text/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20740a48-df1d-4fb8-92f6-10b884a88622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/kunalt/Text/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b7d9372-dcbe-4983-ac9a-6cf908841918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday's ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court's treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What's objectionable is the attempts to undermine international justice, not Palestine's decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court's decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN's Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.\n",
      "\n",
      "Reference Summary:\n",
      "Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
      "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
      "\n",
      "Model Summary:\n",
      "The Palestinian Authority formally becomes the 123rd member of the International Criminal Court . The move gives the court jurisdiction over alleged crimes in Palestinian territories . The United States says it \"strongly\" disagrees with the court's decision .\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "\n",
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
    "\n",
    "\n",
    "\n",
    "sample_text = dataset[\"test\"][0][\"article\"]\n",
    "\n",
    "reference = dataset[\"test\"][0][\"highlights\"]\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"pegasus-cnn-model\",tokenizer=tokenizer)\n",
    "\n",
    "##\n",
    "print(\"Article:\")\n",
    "print(sample_text)\n",
    "\n",
    "\n",
    "print(\"\\nReference Summary:\")\n",
    "print(reference)\n",
    "\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57cb5cc1-f6d0-4312-81c1-14e13cf98c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "(CNN)He's a blue chip college basketball recruit. She's a high school freshman with Down syndrome. At first glance Trey Moses and Ellie Meredith couldn't be more different. But all that changed Thursday when Trey asked Ellie to be his prom date. Trey -- a star on Eastern High School's basketball team in Louisville, Kentucky, who's headed to play college ball next year at Ball State -- was originally going to take his girlfriend to Eastern's prom. So why is he taking Ellie instead? \"She's great... she listens and she's easy to talk to\" he said. Trey made the prom-posal (yes, that's what they are calling invites to prom these days) in the gym during Ellie's P.E. class. Trina Helson, a teacher at Eastern, alerted the school's newspaper staff to the prom-posal and posted photos of Trey and Ellie on Twitter that have gone viral. She wasn't surpristed by Trey's actions. \"That's the kind of person Trey is,\" she said. To help make sure she said yes, Trey entered the gym armed with flowers and a poster that read \"Let's Party Like it's 1989,\" a reference to the latest album by Taylor Swift, Ellie's favorite singer. Trey also got the OK from Ellie's parents the night before via text. They were thrilled. \"You just feel numb to those moments raising a special needs child,\"  said Darla Meredith, Ellie's mom. \"You first feel the need to protect and then to overprotect.\" Darla Meredith said Ellie has struggled with friendships since elementary school, but a special program at Eastern called Best Buddies had made things easier for her. She said Best Buddies cultivates friendships between students with and without developmental disabilities and prevents students like Ellie from feeling isolated and left out of social functions. \"I guess around middle school is when kids started to care about what others thought,\" she said, but \"this school, this year has been a relief.\" Trey's future coach at Ball State, James Whitford, said he felt great about the prom-posal, noting that Trey, whom he's known for a long time, often works with other kids . Trey's mother, Shelly Moses, was also proud of her son. \"It's exciting to bring awareness to a good cause,\" she said. \"Trey has worked pretty hard, and he's a good son.\" Both Trey and Ellie have a lot of planning to do. Trey is looking to take up special education as a college major, in addition to playing basketball in the fall. As for Ellie, she can't stop thinking about prom. \"Ellie can't wait to go dress shopping\" her mother said. \"Because I've only told about a million people!\" Ellie interjected.\n",
      "\n",
      "Reference Summary:\n",
      "College-bound basketball star asks girl with Down syndrome to high school prom .\n",
      "Pictures of the two during the \"prom-posal\" have gone viral .\n",
      "\n",
      "Model Summary:\n",
      "Trey Moses asked Ellie Meredith, a freshman with Down syndrome, to be his prom date . Trey is a star on Eastern High School's basketball team . \"She's great... she listens and she's easy to talk to,\" Trey said .\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "\n",
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
    "\n",
    "\n",
    "\n",
    "sample_text = dataset[\"test\"][5][\"article\"]\n",
    "\n",
    "reference = dataset[\"test\"][5][\"highlights\"]\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"pegasus-cnn-model\",tokenizer=tokenizer)\n",
    "\n",
    "##\n",
    "print(\"Article:\")\n",
    "print(sample_text)\n",
    "\n",
    "\n",
    "print(\"\\nReference Summary:\")\n",
    "print(reference)\n",
    "\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b31a70d1-e70e-41ff-9f76-39410c60792c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "Afghanistan's thumping victory over Pakistan in the ongoing World Cup tournament has created ripples across the world with people now acknowledging the progress made by the war-torn country. Not just Pakistan, the Afghans also defeated the former world champion England in their earlier encounter which goes on to show that it's not just an one-off upset but a concreted effort by a team that has really worked hard on their game.\n",
      "Reacting to this famous win against Pakistan, Taliban lavished huge praise on the Afghanistan cricket team. Khalid Zardan, a Kabul Police spokesperson who is also connected with Taliban said, \"Our cricket team has achieved a historic win. We won a match which many believed was impossible for us. This victory is a message to the people that we are progressing. Watch out for us but do not trouble us.\"The Chief of Staff of the Prime Minister's Office of the Taliban government in Afghanistan has also congratulated the Afghanistan cricket team on their Twitter account.\n",
      "\n",
      "The statement posted on the account reads, \"The Afghanistan national cricket team has defeated Pakistan. Congratulations to the national cricket team, cricket board and all Afghan citizens on this victory.\"\n",
      "\n",
      "Following Afghanistan's historic win against Pakistan, people came out in large numbers and also played music despite an effective ban on song and dance dictated by the Taliban government.\n",
      "About this epic encounter, Afghanistan produced a superb batting and bowling display to chase down a target of 283 set by Pakistan, their highest successful chase in ODI cricket. It was also their first-ever victory over Pakistan in eight ODIs, and came just a week after their shock victory over defending champions England.\n",
      "\n",
      "Afghanistan's bowlers restricted Pakistan to 282 for seven in 50 overs, before their batsmen chased down the target with eight wickets and an over to spare. Ibrahim Zadran top-scored for Afghanistan with 87, while Rahmanullah Gurbaz scored 65 and Rahmat Shah scored 55.\n",
      "\n",
      "Reference Summary:\n",
      "College-bound basketball star asks girl with Down syndrome to high school prom .\n",
      "Pictures of the two during the \"prom-posal\" have gone viral .\n",
      "\n",
      "Model Summary:\n",
      "Afghanistan's thumping victory over Pakistan in the ongoing World Cup has created ripples across the world . Not just Pakistan, the Afghans also defeated the former world champion England in their earlier encounter . Taliban lavished huge praise on the Afghanistan cricket team .\n"
     ]
    }
   ],
   "source": [
    "# summmarization of news articwel\n",
    "#Prediction\n",
    "\n",
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
    "\n",
    "\n",
    "\n",
    "sample_text = '''Afghanistan's thumping victory over Pakistan in the ongoing World Cup tournament has created ripples across the world with people now acknowledging the progress made by the war-torn country. Not just Pakistan, the Afghans also defeated the former world champion England in their earlier encounter which goes on to show that it's not just an one-off upset but a concreted effort by a team that has really worked hard on their game.\n",
    "Reacting to this famous win against Pakistan, Taliban lavished huge praise on the Afghanistan cricket team. Khalid Zardan, a Kabul Police spokesperson who is also connected with Taliban said, \"Our cricket team has achieved a historic win. We won a match which many believed was impossible for us. This victory is a message to the people that we are progressing. Watch out for us but do not trouble us.\"The Chief of Staff of the Prime Minister's Office of the Taliban government in Afghanistan has also congratulated the Afghanistan cricket team on their Twitter account.\n",
    "\n",
    "The statement posted on the account reads, \"The Afghanistan national cricket team has defeated Pakistan. Congratulations to the national cricket team, cricket board and all Afghan citizens on this victory.\"\n",
    "\n",
    "Following Afghanistan's historic win against Pakistan, people came out in large numbers and also played music despite an effective ban on song and dance dictated by the Taliban government.\n",
    "About this epic encounter, Afghanistan produced a superb batting and bowling display to chase down a target of 283 set by Pakistan, their highest successful chase in ODI cricket. It was also their first-ever victory over Pakistan in eight ODIs, and came just a week after their shock victory over defending champions England.\n",
    "\n",
    "Afghanistan's bowlers restricted Pakistan to 282 for seven in 50 overs, before their batsmen chased down the target with eight wickets and an over to spare. Ibrahim Zadran top-scored for Afghanistan with 87, while Rahmanullah Gurbaz scored 65 and Rahmat Shah scored 55.'''\n",
    "\n",
    "#reference = dataset[\"test\"][5][\"highlights\"]\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"pegasus-cnn-model\",tokenizer=tokenizer)\n",
    "\n",
    "##\n",
    "print(\"Article:\")\n",
    "print(sample_text)\n",
    "\n",
    "\n",
    "#print(\"\\nReference Summary:\")\n",
    "#print(reference)\n",
    "\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])\n",
    "\n",
    "################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41218fc-d36b-4361-92ea-55ae0d9fa3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
